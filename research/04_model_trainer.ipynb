{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/HIV_inhibitors_classification_and_generation/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/HIV_inhibitors_classification_and_generation'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    models: Path\n",
    "    stats: Path\n",
    "    source_root: Path\n",
    "    processed_root: Path\n",
    "    source_filename: str\n",
    "    processed_filename: List[str]\n",
    "    tuning: bool\n",
    "    params: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hivclass.constants import *\n",
    "from hivclass.utils.main_utils import create_directories, read_yaml\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_file_path = CONFIG_FILE_PATH,\n",
    "        params_file_path = PARAMS_FILE_PATH,\n",
    "        schema_file_path = SCHEMA_FILE_PATH\n",
    "    ):\n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "        self.schema = read_yaml(schema_file_path)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params\n",
    "        \n",
    "        create_directories([config.root_dir, config.models, config.stats])\n",
    "        \n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            models=Path(config.models),\n",
    "            stats=Path(config.stats),\n",
    "            source_root=config.source_root,\n",
    "            processed_root=config.processed_root,\n",
    "            source_filename=config.source_filename,\n",
    "            processed_filename=config.processed_filename,\n",
    "            tuning=config.tuning,\n",
    "            params=params\n",
    "        )\n",
    "        \n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hivclass.utils.molecule_dataset import MoleculeDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef, confusion_matrix\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hivclass.utils.molecule_dataset import MoleculeDataset\n",
    "from hivclass.utils.mol_gnn import MolGNN\n",
    "from hivclass.utils.main_utils import (\n",
    "    save_json,\n",
    "    plot_metric,\n",
    "    plot_confusion_matrix,\n",
    "    plot_roc_curve,\n",
    "    prepare_yaml_and_inline_lists\n",
    ")\n",
    "import torch \n",
    "from torch_geometric.data import DataLoader\n",
    "from box import ConfigBox\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from mango import Tuner\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "        print(type(self.config.stats))\n",
    "    \n",
    "    def train_val_separation(self, train_dataset):\n",
    "        data_df = pd.read_csv(os.path.join(\n",
    "            self.config.processed_root,\n",
    "            self.config.processed_filename[3]\n",
    "        ))\n",
    "        \n",
    "        train_df, val_df = train_test_split(\n",
    "            data_df,\n",
    "            test_size=self.config.params.data_transformation.val_size,\n",
    "            stratify=data_df.HIV_active,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        train_idxs = train_df.index.tolist()\n",
    "        val_idxs = val_df.index.tolist()\n",
    "        \n",
    "        train = train_dataset.index_select(train_idxs)\n",
    "        val = train_dataset.index_select(val_idxs)\n",
    "        \n",
    "        return train, val\n",
    "    \n",
    "    def train(self, params, epoch, model, train_loader, optimizer, criterion, device):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        train_preds = []\n",
    "        train_labels = []\n",
    "        \n",
    "        for i, batch in tqdm(enumerate(train_loader)):\n",
    "            batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            preds = model(batch.x.float(), batch.edge_attr.float(), batch.edge_index, batch.batch)\n",
    "            train_preds.extend(np.rint(torch.sigmoid(preds).cpu().detach().numpy()))\n",
    "            train_labels.extend(batch.y.cpu().detach().numpy())\n",
    "            \n",
    "            loss = criterion(torch.squeeze(preds), batch.y.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if None not in train_preds:\n",
    "                mcc = matthews_corrcoef(train_labels, train_preds)\n",
    "            else:\n",
    "                mcc = 0.0\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            print()\n",
    "            sys.stdout.write(\n",
    "                \"Epoch:%2d/%2d - Batch:%2d/%2d - train_loss:%.4f - train_mcc:%.4f\" %(\n",
    "                    epoch+1,\n",
    "                    params.num_epochs,\n",
    "                    i,\n",
    "                    len(train_loader),\n",
    "                    loss.item(),\n",
    "                    mcc\n",
    "                )\n",
    "            )\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        return total_loss / len(train_loader), mcc\n",
    "    \n",
    "    def validation(self, epoch, model, val_loader, criterion, best_val_loss, stats_path,  device):\n",
    "        model.eval()\n",
    "        total_loss = 0.0\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader):\n",
    "                batch.to(device)\n",
    "                \n",
    "                preds = model(batch.x.float(), batch.edge_attr.float(), batch.edge_index, batch.batch)\n",
    "                val_preds.extend(np.rint(torch.sigmoid(preds).cpu().detach().numpy()))\n",
    "                val_labels.extend(batch.y.cpu().detach().numpy())\n",
    "                \n",
    "                loss = criterion(torch.squeeze(preds), batch.y.float())\n",
    "                total_loss += loss.item()\n",
    "                mcc = matthews_corrcoef(val_labels, val_preds)\n",
    "            \n",
    "            epoch_loss = total_loss / len(val_loader)\n",
    "            \n",
    "            if epoch_loss < best_val_loss:\n",
    "                report = classification_report(\n",
    "                    val_labels,\n",
    "                    val_preds,\n",
    "                    zero_division=0,\n",
    "                    output_dict=True\n",
    "                )\n",
    "\n",
    "                save_json(\n",
    "                    os.path.join(stats_path, f'report_{epoch}.json'),\n",
    "                    report\n",
    "                )\n",
    "\n",
    "                conf_matrix = confusion_matrix(val_labels, val_preds)\n",
    "\n",
    "                plot_confusion_matrix(\n",
    "                    conf_matrix,\n",
    "                    stats_path,\n",
    "                    epoch\n",
    "                )\n",
    "\n",
    "                auc_score = roc_auc_score(val_labels, val_preds)\n",
    "                auc_score_dict = {'auc_score': auc_score}\n",
    "\n",
    "                save_json(\n",
    "                    os.path.join(stats_path, f'auc_score_{epoch}.json'), \n",
    "                    auc_score_dict\n",
    "                )\n",
    "                \n",
    "                plot_roc_curve(\n",
    "                    val_labels,\n",
    "                    val_preds,\n",
    "                    stats_path,\n",
    "                    epoch\n",
    "                )\n",
    "                \n",
    "        return epoch_loss, mcc\n",
    "    \n",
    "    def train_compose(self):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(\"device:\", device)\n",
    "        print(type(self.config.stats))\n",
    "        \n",
    "        dataset = MoleculeDataset(\n",
    "            self.config.source_root,\n",
    "            self.config.processed_root,\n",
    "            self.config.source_filename,\n",
    "            self.config.processed_filename\n",
    "        )\n",
    "        \n",
    "        train_dataset, val_dataset = self.train_val_separation(dataset)\n",
    "        \n",
    "        def train_tuning(params):\n",
    "            try:\n",
    "                params = params[0]\n",
    "                \n",
    "                if self.config.tuning:\n",
    "                    folder_name = str(len(os.listdir(self.config.stats)) + 1)\n",
    "                else:\n",
    "                    folder_name = \"best_retrain\"\n",
    "                \n",
    "                models_path = os.path.join(self.config.models, folder_name)\n",
    "                stats_path = os.path.join(self.config.stats, folder_name)\n",
    "                \n",
    "                create_directories([models_path, stats_path])\n",
    "\n",
    "                # params_dict = params.to_dict()\n",
    "                # params_yaml = prepare_yaml_and_inline_lists(params_dict)\n",
    "\n",
    "                # with open(os.path.join(stats_path, \"params.yaml\"), 'w') as file:\n",
    "                #     file.write(params_yaml)\n",
    "                \n",
    "                with open(os.path.join(stats_path, \"params.yaml\"), 'w') as file:\n",
    "                    file.write(yaml.dump(params, sort_keys=False))\n",
    "                \n",
    "                params = ConfigBox(params)\n",
    "                \n",
    "                train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=params['batch_size'], shuffle=False)\n",
    "                params[\"model_edge_dim\"] = train_dataset[0].edge_attr.shape[1]\n",
    "                \n",
    "                print(\"Loading model...\")\n",
    "                model_params = ConfigBox({k: v for k, v in params.items() if k.startswith(\"model_\")})\n",
    "                model = MolGNN(feature_size=train_dataset[0].x.shape[1], model_params=model_params)\n",
    "                model = model.to(device)\n",
    "                \n",
    "                weight = torch.tensor([params[\"pos_weight\"]], dtype=torch.float32).to(device)\n",
    "                criterion = torch.nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "                optimizer = torch.optim.SGD(\n",
    "                    model.parameters(),\n",
    "                    lr=params['learning_rate'],\n",
    "                    momentum=params['sgd_momentum'],\n",
    "                    weight_decay=params['weight_decay']\n",
    "                )\n",
    "                \n",
    "                scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=params.scheduler_gamma)\n",
    "                \n",
    "                train_losses = []\n",
    "                val_losses = []\n",
    "                train_mcc = []\n",
    "                val_mcc = []\n",
    "                best_val_loss = float('inf')\n",
    "                early_stopping_counter = 0\n",
    "                \n",
    "                for epoch in tqdm(range(params.num_epochs)):\n",
    "                    if early_stopping_counter <= params.early_stopping:\n",
    "                        train_epoch_loss, train_epoch_mcc = self.train(\n",
    "                            params,\n",
    "                            epoch,\n",
    "                            model,\n",
    "                            train_loader,\n",
    "                            optimizer,\n",
    "                            criterion,\n",
    "                            device\n",
    "                        )\n",
    "                        \n",
    "                        train_losses.append(train_epoch_loss)\n",
    "                        train_mcc.append(train_epoch_mcc)\n",
    "                        \n",
    "                        val_epoch_loss, val_epoch_mcc = self.validation(\n",
    "                            epoch,\n",
    "                            model,\n",
    "                            val_loader,\n",
    "                            criterion,\n",
    "                            best_val_loss,\n",
    "                            stats_path,\n",
    "                            device\n",
    "                        )\n",
    "                        \n",
    "                        val_losses.append(val_epoch_loss)\n",
    "                        val_mcc.append(val_epoch_mcc)\n",
    "                        \n",
    "                        print(f'Epoch [{epoch+1}/{params.num_epochs}], '\n",
    "                            f'Loss: {train_epoch_loss:.4f}, '\n",
    "                            f'Validation Loss: {val_epoch_loss:.4f}, '\n",
    "                            f'Train Accuracy: {train_epoch_mcc:.2f}%, '\n",
    "                            f'Validation Accuracy: {val_epoch_mcc:.2f}%')\n",
    "                        \n",
    "                        if float(val_epoch_loss) < best_val_loss:\n",
    "                            torch.save(model.state_dict(), os.path.join(models_path, f'model_{epoch}.pth'))\n",
    "                            best_val_loss = float(val_epoch_loss)\n",
    "                            early_stopping_counter = 0\n",
    "                        else:\n",
    "                            early_stopping_counter += 1\n",
    "                        \n",
    "                        scheduler.step()\n",
    "                    else:\n",
    "                        print(\"Early stopping due to no improvement.\")\n",
    "                        epochs_range = range(1, len(train_losses) + 1)\n",
    "                        \n",
    "                        plot_metric(\n",
    "                            stats_path,\n",
    "                            epochs_range,\n",
    "                            train_losses,\n",
    "                            val_losses,\n",
    "                            'Train Loss',\n",
    "                            'Validation Loss',\n",
    "                        )\n",
    "                        \n",
    "                        plot_metric(\n",
    "                            stats_path,\n",
    "                            epochs_range,\n",
    "                            train_mcc,\n",
    "                            val_mcc,\n",
    "                            'Train Accuracies',\n",
    "                            'Validation Accuracies',\n",
    "                        )\n",
    "                        \n",
    "                        return [best_val_loss]\n",
    "                \n",
    "                print(f\"Finishing training with best test loss: {best_val_loss}\")\n",
    "                epochs_range = range(1, params.num_epochs + 1)\n",
    "\n",
    "                plot_metric(\n",
    "                    stats_path,\n",
    "                    epochs_range,\n",
    "                    train_losses,\n",
    "                    val_losses,\n",
    "                    'Train Loss',\n",
    "                    'Validation Loss',\n",
    "                )\n",
    "                \n",
    "                plot_metric(\n",
    "                    stats_path,\n",
    "                    epochs_range,\n",
    "                    train_mcc,\n",
    "                    val_mcc,\n",
    "                    'Train Accuracies',\n",
    "                    'Validation Accuracies',\n",
    "                )\n",
    "                \n",
    "                return [best_val_loss]\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Training failed for params: {params}\")\n",
    "                print(f\"[ERROR] Exception: {e}\")\n",
    "\n",
    "                # return a large loss so Mango avoids this config\n",
    "                return [float('inf')]\n",
    "        \n",
    "        if self.config.tuning:\n",
    "            print(\"Running hyperparameter search...\")\n",
    "            params = self.config.params.HYPERPARAMETERS\n",
    "            config = dict()\n",
    "            config[\"optimizer\"] = params.tuning_optimizer[0]\n",
    "            config[\"num_iteration\"] = params.tuning_iterations[0]\n",
    "            \n",
    "            tuner = Tuner(params, objective=train_tuning, conf_dict=config)\n",
    "            \n",
    "            results = tuner.minimize()\n",
    "            \n",
    "            self.config.params['BEST_PARAMETERS'] = results['best_params']\n",
    "            params_dict = self.config.params.to_dict()\n",
    "            params_yaml = prepare_yaml_and_inline_lists(params_dict)\n",
    "            # best_params = yaml.safe_dump(self.config.params.to_dict(), sort_keys=False, default_flow_style=True)\n",
    "            \n",
    "            with open(PARAMS_FILE_PATH, 'w') as file:\n",
    "                file.write(params_yaml)\n",
    "            \n",
    "            for folder in os.listdir(self.config.stats):\n",
    "                params_path = self.config.stats.joinpath(folder, 'params.yaml')\n",
    "                tuning_params = read_yaml(params_path)\n",
    "                \n",
    "                if self.config.params['BEST_PARAMETERS'] == tuning_params:\n",
    "                    best_stats_folder_path = self.config.stats.joinpath(folder)\n",
    "                    best_model_folder_path = self.config.models.joinpath(folder)\n",
    "                    \n",
    "                    try:\n",
    "                        best_stats_folder_path.rename(self.config.stats.joinpath('best_params'))\n",
    "                        print(f\"Folder renamed from {best_stats_folder_path} to {self.config.stats.joinpath('best_params')}\")\n",
    "                    except FileNotFoundError:\n",
    "                        print(f\"Error: The folder {best_stats_folder_path} does not exist.\")\n",
    "                    except FileExistsError:\n",
    "                        print(f\"Error: A folder named {self.config.stats.joinpath('best_params')} already exists.\")\n",
    "                    except PermissionError:\n",
    "                        print(f\"Error: Permission denied to rename the folder.\")\n",
    "                    \n",
    "                    try:\n",
    "                        best_model_folder_path.rename(self.config.models.joinpath('best_params'))\n",
    "                        print(f\"Folder renamed from {best_stats_folder_path} to {self.config.stats.joinpath('best_params')}\")\n",
    "                    except FileNotFoundError:\n",
    "                        print(f\"Error: The folder {best_model_folder_path} does not exist.\")\n",
    "                    except FileExistsError:\n",
    "                        print(f\"Error: A folder named {self.config.models.joinpath('best_params')} already exists.\")\n",
    "                    except PermissionError:\n",
    "                        print(f\"Error: Permission denied to rename the folder.\")\n",
    "        else:\n",
    "            print(type(self.config.stats))\n",
    "            # params = self.config.params.BEST_PARAMETERS\n",
    "            # params = params.to_dict()\n",
    "            # _ = train_tuning([params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-01 16:46:35,327: INFO: main_utils: created directory at: artifacts]\n",
      "[2025-05-01 16:46:35,329: INFO: main_utils: created directory at: artifacts/model_trainer]\n",
      "[2025-05-01 16:46:35,329: INFO: main_utils: created directory at: artifacts/model_trainer/models]\n",
      "[2025-05-01 16:46:35,330: INFO: main_utils: created directory at: artifacts/model_trainer/stats]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pathlib.PosixPath'>\n",
      "device: cuda\n",
      "<class 'pathlib.PosixPath'>\n",
      "<class 'pathlib.PosixPath'>\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer = ModelTrainer(config=model_trainer_config)\n",
    "    results = model_trainer.train_compose()\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
