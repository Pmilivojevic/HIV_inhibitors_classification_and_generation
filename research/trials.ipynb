{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/HIV_inhibitors_classification_and_generation/research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/HIV_inhibitors_classification_and_generation'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "No normalization for NumAmideBonds. Feature removed!\n",
      "No normalization for NumAtomStereoCenters. Feature removed!\n",
      "No normalization for NumBridgeheadAtoms. Feature removed!\n",
      "No normalization for NumHeterocycles. Feature removed!\n",
      "No normalization for NumSpiroAtoms. Feature removed!\n",
      "No normalization for NumUnspecifiedAtomStereoCenters. Feature removed!\n",
      "No normalization for Phi. Feature removed!\n",
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torchdata.datapipes'\n",
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/HIV_inhibitors_classification_and_generation/env/lib/python3.10/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "Skipped loading some PyTorch models, missing a dependency. No module named 'tensorflow'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "import deepchem as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiv = pd.read_csv('artifacts/data_ingestion/HIV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_t_split_balance(df, split_size):\n",
    "    # Separate positive and negative cases\n",
    "    p_val = df[df.HIV_active == 1].to_numpy()\n",
    "    n_val = df[df.HIV_active == 0].to_numpy()\n",
    "\n",
    "    # Ensure class balance by selecting the smaller group as the target\n",
    "    if len(p_val) >= len(n_val):\n",
    "        big, small = p_val, n_val\n",
    "    else:\n",
    "        big, small = n_val, p_val\n",
    "\n",
    "    # Stratified test split\n",
    "    small_train, small_test = train_test_split(small, test_size=split_size, random_state=42)\n",
    "    big_train, big_test = train_test_split(big, test_size=(split_size * len(small) / len(big)), random_state=42)\n",
    "\n",
    "    test = np.concatenate([small_test, big_test])\n",
    "    \n",
    "    # Ensure the train set remains balanced by oversampling the smaller class\n",
    "    train = np.concatenate([big_train, random.choices(small_train, k=len(big_train) - len(small_train))])\n",
    "\n",
    "    # Convert back to DataFrame\n",
    "    train_df = pd.DataFrame(train, columns=df.columns)\n",
    "    test_df = pd.DataFrame(test, columns=df.columns)\n",
    "\n",
    "    return train_df.sample(frac=1, random_state=42), test_df.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = t_t_split_balance(hiv, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list = p_df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = random.choices(p_list, k=int(0.2*len(p_list)))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in hiv.head().iterrows():\n",
    "    if hiv.eq(row[1]).all(axis=1).any():\n",
    "        print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if list(test_df.columns) == ['smils', 'activity', 'HIV_active']:\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['HIV_active'][0] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool(test_df['HIV_active'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pth = 'artifacts/data_transformation/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = train_pth.split('/')[-1].split('.')[0]\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('artifacts/data_transformation/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CCCc1cc(=O)oc2c3c(cc(OC(C)CC)c12)OC(C)C(C)C3O'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.smiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_obj = Chem.MolFromSmiles(train.smiles[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for atom in mol_obj.GetAtoms():\n",
    "    print(atom.GetSymbol(), atom.GetChiralTag())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonds = mol_obj.GetBonds()\n",
    "\n",
    "for bond in bonds:\n",
    "    print(bond.GetBeginAtom().GetAtomicNum())\n",
    "    print(bond.GetIsConjugated())\n",
    "    print(bond.GetEndAtom().GetAtomicNum())\n",
    "    print('___')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "        1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "        1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "f = featurizer._featurize(mol_obj)\n",
    "# data = f.to_pyg_graph()\n",
    "f.node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {name: pd.read_csv(csv) for name, csv in \n",
    "                zip([\"train\", \"test\"], ['artifacts/data_transformation/train.csv', 'artifacts/data_transformation/test.csv'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train':                                                   smiles activity  HIV_active\n",
       " 0          CCCc1cc(=O)oc2c3c(cc(OC(C)CC)c12)OC(C)C(C)C3O       CM           1\n",
       " 1                Cn1c2ccccc2n2c(=O)c(-c3ccc(Cl)cc3)nnc12       CI           0\n",
       " 2                  COc1ccc(NC(=O)CC(=O)Nc2ccc(OC)cc2)cc1       CI           0\n",
       " 3      CC(C)CCCC(C)C1CCC2C3CCC4CC(CCC=C(c5cc(Br)c(O)c...       CA           1\n",
       " 4                               COC=C1C(=O)OC(C)(C)OC1=O       CM           1\n",
       " ...                                                  ...      ...         ...\n",
       " 77631                Cn1c2ccccc2c2ccc3c(c21)C(=O)C=CC3=O       CI           0\n",
       " 77632                   Clc1cccc(Cl)c1C1SCc2nc3ncccc3n21       CM           1\n",
       " 77633  CCC(=O)CCCC=C(c1cc(Cl)c(OC)c(C(=O)OC)c1)c1cc(C...       CA           1\n",
       " 77634          CN1C(=O)C(=NN(c2ccccc2)c2ccccc2)c2ccccc21       CI           0\n",
       " 77635  CCOC(=O)C(Cc1c(C=O)[nH]c2ccccc12)(NC(=O)c1cccc...       CI           0\n",
       " \n",
       " [77636 rows x 3 columns],\n",
       " 'test':                                                 smiles activity  HIV_active\n",
       " 0                                        OCC1(CO)CSSC1       CM           1\n",
       " 1    CC=C(C)C(=O)OCC12C(OC(C)=O)CC(C)C(C)(CCC3=CC(=...       CI           0\n",
       " 2              COC(=O)CCCc1ccc2c(c1)CC1(Cc3ccccc3C1)C2       CI           0\n",
       " 3    Cn1cc(NC(=O)c2cc([N+](=O)[O-])cn2C)cc1C(=O)Nc1...       CM           1\n",
       " 4           COC(C(=O)NCCCCNC(=O)C(OC)c1ccccc1)c1ccccc1       CI           0\n",
       " ..                                                 ...      ...         ...\n",
       " 573      CCOC(=O)C(=Cc1c(C)[nH]c2ccccc12)P(=O)(OCC)OCC       CM           1\n",
       " 574                    O=S(=O)(c1ccccc1)c1cccc2c1NCCC2       CM           1\n",
       " 575      COC(=O)c1cc(CC2Cc3cc4c(cc3C2=O)CCC4)cc2c1CCC2       CM           1\n",
       " 576                        CC(C)(O)C=CP(C)(=O)c1ccccc1       CI           0\n",
       " 577                       CC1(c2ccccc2)CCCCC1=NNC(N)=O       CM           1\n",
       " \n",
       " [578 rows x 3 columns]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
